# MLOps Course Presentation
# 0‚Üí1‚ÜíProduction (Commands-First)

> A Visual Guide for Teaching MLOps to Students
> 
> **Duration**: 25-30 hours total | **Modules**: 15 | **Level**: Beginner to Advanced

---

## üéØ Slide 1: Course Overview

### MLOps Course: Complete Journey from Development to Production

**What Students Will Learn:**
- ‚úÖ Version data, code, and models for full reproducibility
- ‚úÖ Track experiments and systematically compare models
- ‚úÖ Build automated pipelines for training and deployment
- ‚úÖ Serve models via APIs with monitoring and autoscaling
- ‚úÖ Detect drift and trigger automated retraining
- ‚úÖ Deploy with CI/CD to multiple environments
- ‚úÖ Monitor production systems with metrics and alerts
- ‚úÖ Secure and optimize ML systems for cost and compliance

**Target Audience:**
- Data Scientists wanting to operationalize models
- ML Engineers building production pipelines
- DevOps/Platform Engineers supporting ML workloads
- Software Engineers transitioning to ML systems
- Beginners with no data science background (special module included!)

---

## üìö Slide 2: Course Structure

### 15 Comprehensive Modules

| Phase | Modules | Focus Area | Duration |
|-------|---------|------------|----------|
| **Foundations** | 00-04 | Setup, Environment, Data, Experiments | 6.5 hours |
| **Pipelines** | 05-07 | Orchestration, Training, Registry | 6 hours |
| **Serving** | 08-10 | APIs, Batch/Streaming, CI/CD | 7 hours |
| **Production** | 11-14 | Monitoring, Drift, Security, Review | 6 hours |

**Teaching Approach**: Commands First, Minimal Theory, Maximum Practice

**Learning Materials:**
- 150+ pages of practical content
- 14 hands-on mini-labs (5-10 min each)
- 70+ quiz questions
- Full production-ready capstone project
- 2 mock certification exams
- 3 comprehensive cheatsheets
- 50+ troubleshooting solutions

---

## üèóÔ∏è Slide 3: System Architecture

### What Students Will Build

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    PRODUCTION ML SYSTEM                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

   DATA LAYER                TRAINING LAYER           SERVING LAYER
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Raw Data   ‚îÇ          ‚îÇ   Airflow    ‚îÇ         ‚îÇ   FastAPI    ‚îÇ
‚îÇ              ‚îÇ‚îÄ‚îÄDVC‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   Pipeline   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ     API      ‚îÇ
‚îÇ  S3/MinIO    ‚îÇ          ‚îÇ              ‚îÇ         ‚îÇ              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                 ‚îÇ                         ‚îÇ
                                 ‚îÇ                         ‚îÇ
                                 ‚ñº                         ‚ñº
                          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                          ‚îÇ    MLflow    ‚îÇ         ‚îÇ  Kubernetes  ‚îÇ
                          ‚îÇ  Tracking &  ‚îÇ         ‚îÇ  Deployment  ‚îÇ
                          ‚îÇ   Registry   ‚îÇ         ‚îÇ              ‚îÇ
                          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                           ‚îÇ
                                                           ‚îÇ
   MONITORING LAYER                                        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Prometheus  ‚Üí  Grafana  ‚Üí  Alerts  ‚Üí  Drift Detection          ‚îÇ
‚îÇ                                                                   ‚îÇ
‚îÇ  If drift detected  ‚Üí  Trigger Automated Retraining  ‚Üª          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Complete Cycle**: Data ‚Üí Train ‚Üí Deploy ‚Üí Monitor ‚Üí Retrain

---

## üìñ Slide 4: Module 00-01 - Foundations

### Getting Started with MLOps

**Module 00: Overview**
- Course philosophy: Commands first, theory second
- Three practice environments: Local ‚Üí K8s ‚Üí Cloud
- Setting up the learning environment
- Course variables and configuration

**Module 00.5: Data Engineering for Beginners** ‚≠ê NEW!
- Perfect for DevOps engineers with no data background
- Data gathering, cleaning, and exploration
- Feature engineering basics
- Introduction to machine learning concepts
- Duration: 2 hours

**Module 01: MLOps Foundations**
- ML lifecycle: Development ‚Üí Staging ‚Üí Production
- Key roles: Data Scientists, ML Engineers, DevOps
- Artifacts: Data, Code, Models, Configurations
- Dev-prod parity and reproducibility

**Key Takeaway**: MLOps is about making ML systems reliable, scalable, and maintainable in production.

---

## üêç Slide 5: Module 02 - Environment & Packaging

### Python Environment Management

**What Students Learn:**
- Modern Python tools: `uv` and `poetry`
- Dependency management with `pyproject.toml`
- Lock files for reproducibility
- Docker containerization
- Multi-stage builds for optimization
- Pre-commit hooks for code quality

**Hands-On:**
```bash
# Initialize project with uv
uv init my-ml-project
uv add pandas scikit-learn mlflow

# Create Docker container
docker build -t ml-app:latest .
docker run -p 8000:8000 ml-app

# Setup pre-commit hooks
pre-commit install
pre-commit run --all-files
```

**Key Takeaway**: Proper environment management prevents "works on my machine" problems.

---

## üìä Slide 6: Module 03 - Data Versioning & Quality

### Managing Data Like Code

**DVC (Data Version Control):**
- Version large datasets efficiently
- Track data lineage
- Share data via remote storage (S3, GCS, Azure)
- Reproduce experiments with exact data versions

**Data Quality Checks:**
- Great Expectations: Validate data schemas
- Evidently: Monitor data quality
- Automated alerts for data issues

**Hands-On:**
```bash
# Initialize DVC
dvc init
dvc remote add -d storage s3://mlops-data

# Track dataset
dvc add data/raw/customers.csv
git add data/raw/customers.csv.dvc
git commit -m "Add customer data v1"

# Push data to remote
dvc push
```

**Key Takeaway**: Data versioning is as important as code versioning for reproducibility.

---

## üî¨ Slide 7: Module 04 - Experiment Tracking

### MLflow for Experiment Management

**What Students Learn:**
- Log parameters, metrics, and artifacts
- Compare multiple experiment runs
- Organize experiments by projects
- Track model lineage
- Save and load models

**Hands-On:**
```python
import mlflow
import mlflow.sklearn

# Start MLflow tracking
mlflow.set_experiment("churn-prediction")

with mlflow.start_run():
    # Log parameters
    mlflow.log_param("max_depth", 5)
    mlflow.log_param("n_estimators", 100)
    
    # Train model
    model = RandomForestClassifier(max_depth=5, n_estimators=100)
    model.fit(X_train, y_train)
    
    # Log metrics
    accuracy = model.score(X_test, y_test)
    mlflow.log_metric("accuracy", accuracy)
    
    # Save model
    mlflow.sklearn.log_model(model, "model")
```

**Key Takeaway**: Track everything - even failed experiments provide valuable insights.

---

## üîÑ Slide 8: Module 05 - Pipelines & Orchestration

### Automating ML Workflows

**Workflow Orchestration:**
- Apache Airflow: Python-based DAGs
- Kubeflow Pipelines: Kubernetes-native workflows
- DAGs (Directed Acyclic Graphs)
- Task dependencies and retries
- Idempotent operations

**Example Pipeline Stages:**
1. Data Validation
2. Feature Engineering
3. Model Training
4. Model Evaluation
5. Model Registration
6. Deployment

**Hands-On:**
```python
from airflow import DAG
from airflow.operators.python import PythonOperator

dag = DAG('ml_training_pipeline', schedule_interval='@daily')

validate_task = PythonOperator(
    task_id='validate_data',
    python_callable=validate_data,
    dag=dag
)

train_task = PythonOperator(
    task_id='train_model',
    python_callable=train_model,
    dag=dag
)

validate_task >> train_task  # Set dependency
```

**Key Takeaway**: Automation ensures consistency and enables continuous learning.

---

## üéØ Slide 9: Module 06 - Training, Evaluation & Selection

### Systematic Model Development

**What Students Learn:**
- Cross-validation strategies
- Hyperparameter tuning (Grid Search, Random Search, Bayesian)
- Model evaluation metrics
- Bias detection and fairness
- Model comparison and selection

**Best Practices:**
- Use stratified splits for imbalanced data
- Always have a validation set
- Log all hyperparameters
- Check for bias across demographic groups
- Document model limitations

**Hands-On:**
```python
from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestClassifier

param_grid = {
    'max_depth': [3, 5, 7],
    'n_estimators': [50, 100, 200]
}

grid_search = GridSearchCV(
    RandomForestClassifier(),
    param_grid,
    cv=5,
    scoring='accuracy'
)

grid_search.fit(X_train, y_train)
best_model = grid_search.best_estimator_
```

**Key Takeaway**: Systematic evaluation prevents overfitting and ensures model quality.

---

## üìã Slide 10: Module 07 - Model Registry & Governance

### Managing Models in Production

**MLflow Model Registry:**
- Central repository for models
- Model versioning
- Stage transitions (Staging ‚Üí Production)
- Model approval workflows
- Model metadata and lineage

**Model Governance:**
- Model cards: Purpose, performance, limitations
- Approval gates before production
- Model retirement policies
- Audit trails for compliance

**Hands-On:**
```python
import mlflow

# Register model
mlflow.register_model(
    "runs:/<run_id>/model",
    "churn-predictor"
)

# Transition to production
client = mlflow.MlflowClient()
client.transition_model_version_stage(
    name="churn-predictor",
    version=3,
    stage="Production"
)
```

**Key Takeaway**: Model registry provides governance and traceability for production models.

---

## üöÄ Slide 11: Module 08 - Serving & APIs

### Deploying Models as Services

**What Students Learn:**
- REST API development with FastAPI
- Model loading and inference
- Health checks and readiness probes
- API documentation (OpenAPI/Swagger)
- Alternative serving options: KServe, BentoML

**Best Practices:**
- Load model once at startup (not per request)
- Implement proper error handling
- Add request validation
- Include monitoring metrics
- Version your API

**Hands-On:**
```python
from fastapi import FastAPI
import mlflow.pyfunc

app = FastAPI()
model = mlflow.pyfunc.load_model("models:/churn-predictor/Production")

@app.get("/health")
async def health():
    return {"status": "healthy"}

@app.post("/predict")
async def predict(features: dict):
    prediction = model.predict([features["data"]])
    return {"prediction": prediction.tolist()}
```

**Key Takeaway**: Well-designed APIs make models accessible and maintainable.

---

## üì¶ Slide 12: Module 09 - Batch & Streaming

### Large-Scale Inference

**Batch Processing:**
- Process large datasets offline
- Scheduled batch jobs
- Optimize for throughput
- Store predictions for later use

**Streaming Inference:**
- Real-time event processing
- Apache Kafka integration
- Low-latency predictions
- Handling backpressure

**Use Cases:**
- Batch: Daily customer scoring, periodic reporting
- Streaming: Fraud detection, recommendation systems

**Hands-On:**
```python
# Batch scoring
import pandas as pd

data = pd.read_csv("customers.csv")
predictions = model.predict(data)
pd.DataFrame(predictions).to_csv("predictions.csv")

# Streaming with Kafka
from kafka import KafkaConsumer, KafkaProducer

consumer = KafkaConsumer('input-events')
producer = KafkaProducer('predictions')

for message in consumer:
    data = json.loads(message.value)
    prediction = model.predict([data])
    producer.send('predictions', prediction)
```

**Key Takeaway**: Choose batch or streaming based on latency requirements.

---

## üîß Slide 13: Module 10 - CI/CD & Environments

### Automated Deployment Pipelines

**What Students Learn:**
- GitHub Actions for CI/CD
- Multi-environment strategy (Dev, Staging, Production)
- Automated testing in CI
- Security scanning (Trivy, Gitleaks)
- Deployment strategies: Canary, Blue-Green, Rolling

**CI/CD Pipeline Stages:**
1. Code quality checks (linting, formatting)
2. Unit and integration tests
3. Security scanning
4. Build Docker images
5. Push to registry
6. Deploy to environment
7. Run smoke tests

**Best Practices:**
- Separate configs per environment
- Manual approval gates for production
- Rollback procedures
- Infrastructure as Code

**Key Takeaway**: Automation reduces errors and speeds up delivery.

---

## üìä Slide 14: Module 11 - Observability & Monitoring

### Production System Health

**Golden Signals:**
- **Latency**: Response time
- **Traffic**: Request rate
- **Errors**: Error rate
- **Saturation**: Resource utilization

**Tools:**
- Prometheus: Metrics collection
- Grafana: Visualization and dashboards
- OpenTelemetry: Distributed tracing
- Alerts: PagerDuty, Slack

**What to Monitor:**
- API latency and throughput
- Prediction distribution
- Model accuracy (when ground truth available)
- Resource usage (CPU, memory, GPU)
- Data quality metrics

**SLIs, SLOs, SLAs:**
- SLI: Service Level Indicator (actual measurement)
- SLO: Service Level Objective (target)
- SLA: Service Level Agreement (contract)

**Key Takeaway**: You can't improve what you don't measure.

---

## üîç Slide 15: Module 12 - Drift Detection & Retraining

### Keeping Models Fresh

**Types of Drift:**
- **Data Drift**: Input distribution changes
- **Concept Drift**: Relationship between inputs and outputs changes
- **Prediction Drift**: Output distribution changes

**Detection with Evidently:**
- Statistical tests for drift
- Distribution comparisons
- Automated alerts
- Dashboard visualization

**Automated Retraining:**
1. Monitor for drift
2. Trigger alert when threshold exceeded
3. Automatically start training pipeline
4. Evaluate new model
5. Deploy if better than current

**Hands-On:**
```python
from evidently.report import Report
from evidently.metric_preset import DataDriftPreset

report = Report(metrics=[DataDriftPreset()])
report.run(reference_data=train_data, current_data=production_data)

if report.as_dict()['metrics'][0]['result']['dataset_drift']:
    trigger_retraining_pipeline()
```

**Key Takeaway**: Proactive drift detection prevents model degradation.

---

## üîí Slide 16: Module 13 - Security, Compliance & Cost

### Production Best Practices

**Security:**
- CVE scanning with Trivy
- Secret management (never commit secrets!)
- SBOM (Software Bill of Materials)
- PII detection and masking
- Access control and authentication

**Compliance:**
- Model documentation (model cards)
- Audit trails
- Data governance
- GDPR/CCPA compliance
- Explainability for regulated industries

**Cost Optimization (FinOps):**
- Resource limits and quotas
- Autoscaling policies
- Right-sizing instances
- Cost monitoring and alerts
- Spot/preemptible instances

**Key Takeaway**: Security and cost management are non-negotiable in production.

---

## üéì Slide 17: Module 14 - Comprehensive Review

### Bringing It All Together

**End-to-End Scenario:**
1. Version data with DVC
2. Build training pipeline with Airflow
3. Track experiments with MLflow
4. Register best model
5. Deploy API with FastAPI
6. Monitor with Prometheus + Grafana
7. Detect drift with Evidently
8. Trigger automated retraining

**Troubleshooting Skills:**
- Reading logs effectively
- Using metrics to diagnose issues
- Common problems and solutions
- When to scale vs optimize

**Career Paths:**
- ML Engineer
- MLOps Engineer
- Platform Engineer (ML-focused)
- Data Scientist (MLOps-savvy)

**Key Takeaway**: You now have the skills to build production ML systems!

---

## üèÜ Slide 18: Capstone Project - Churn Predictor

### Real-World Production System

**Project Overview:**
Build a complete customer churn prediction system from scratch

**Features:**
- Data versioning (DVC + S3/MinIO)
- Automated training pipeline (Airflow)
- Experiment tracking (MLflow)
- Model registry with governance
- REST API (FastAPI) with monitoring
- Batch scoring for large datasets
- Drift detection and automated retraining
- CI/CD with GitHub Actions
- Kubernetes deployment with autoscaling
- Comprehensive monitoring (Prometheus + Grafana)

**Tech Stack:**
- Python, Docker, Kubernetes
- MLflow, DVC, Airflow
- FastAPI, Prometheus, Grafana
- GitHub Actions

**Deliverables:**
- Fully functional ML system
- Documentation and runbooks
- Test coverage
- Monitoring dashboards

---

## üõ†Ô∏è Slide 19: Technology Stack

### Tools You'll Master

**Python Ecosystem:**
- Environment: uv, poetry, pyproject.toml
- Quality: black, ruff, mypy, pre-commit
- Testing: pytest, coverage

**ML Tools:**
- Data: DVC, Great Expectations, Evidently
- Experiments: MLflow
- Fairness: fairlearn

**Infrastructure:**
- Containers: Docker, docker-compose
- Orchestration: Kubernetes, Kustomize, Helm
- IaC: Terraform
- CI/CD: GitHub Actions

**Observability:**
- Metrics: Prometheus, Grafana
- Tracing: OpenTelemetry, Jaeger

**Workflow:**
- Orchestration: Airflow, Kubeflow Pipelines
- Serving: FastAPI, KServe, BentoML

**Security:**
- Scanning: Trivy, Gitleaks
- SBOM: Syft

---

## üìö Slide 20: Supporting Materials

### Beyond the Core Modules

**Cheatsheets (50+ pages):**
1. Python Environment Management
   - uv, poetry, pip, conda comparison
   - Docker best practices
2. DVC + MLflow
   - Complete command reference
   - Integration patterns
3. Docker & Kubernetes
   - Container management
   - K8s manifests and deployments
4. Linux for MLOps/DevOps ‚≠ê NEW!
   - Essential commands for ML workflows

**Troubleshooting Matrix:**
- 50+ common issues with solutions
- Organized by category
- Triage commands for each issue
- Prevention strategies

**Mock Exams:**
- 2 comprehensive exams (90 minutes each)
- 100 points per exam
- Real-world scenarios
- Certification-style questions

---

## üéØ Slide 21: Learning Outcomes

### What Students Can Do After This Course

**Technical Skills:**
‚úÖ Version data, code, and models for full reproducibility
‚úÖ Track experiments and select best models systematically
‚úÖ Build automated training and deployment pipelines
‚úÖ Serve models via APIs with health checks and monitoring
‚úÖ Deploy to Kubernetes with autoscaling
‚úÖ Implement CI/CD with security scanning
‚úÖ Monitor production systems with metrics and alerts
‚úÖ Detect drift and trigger automated retraining
‚úÖ Secure systems (CVE scanning, secrets management, PII)
‚úÖ Optimize costs with resource limits and autoscaling

**Soft Skills:**
‚úÖ Read and write Infrastructure as Code
‚úÖ Debug production issues with logs and metrics
‚úÖ Design for observability and maintainability
‚úÖ Document systems (model cards, runbooks)
‚úÖ Collaborate using GitOps workflows

---

## üíº Slide 22: Career Opportunities

### MLOps Career Paths & Salaries

**ML Engineer**
- Productionize models
- Build ML pipelines
- Optimize inference performance
- **Avg Salary**: $130k-$180k (US, 2024)

**MLOps Engineer**
- Build ML infrastructure
- Maintain CI/CD pipelines
- Implement monitoring and alerting
- **Avg Salary**: $140k-$190k (US, 2024)

**Platform Engineer (ML-focused)**
- Design scalable ML platforms
- Manage Kubernetes clusters
- Optimize costs
- **Avg Salary**: $150k-$200k (US, 2024)

**Data Scientist (MLOps-savvy)**
- Experiment + Deploy
- End-to-end ownership
- Bridge research and production
- **Avg Salary**: $120k-$170k (US, 2024)

**Market Demand**: Growing rapidly - MLOps roles increased 300% in 2023

---

## üöÄ Slide 23: Three-Tier Learning Path

### Start Simple, Level Up Gradually

**Tier 1: Local Development (Weeks 1-2)**
- Run everything with Docker Compose
- Complete modules 00-04
- Learn fundamentals
- Build confidence

**Tier 2: Kubernetes Practice (Weeks 3-4)**
- Deploy to K3d or Minikube
- Complete modules 05-09
- Learn container orchestration
- Practice DevOps patterns

**Tier 3: Cloud Production (Weeks 5-6)**
- Deploy to AWS/GCP/Azure
- Complete modules 10-14
- Learn cloud services
- Master production patterns

**Flexibility**: Move at your own pace, skip tiers if experienced

---

## ‚è±Ô∏è Slide 24: Time Commitment

### Course Timeline

**Total Duration**: 25-30 hours

**Beginner Track (2 weeks, 15 hours/week):**
- Week 1: Modules 00-04 (Foundations)
- Week 2: Modules 05-07 (Pipelines & Training)

**Intermediate Track (2 weeks, 10 hours/week):**
- Week 3: Modules 08-10 (Serving & CI/CD)
- Week 4: Modules 11-12 (Monitoring & Drift)

**Advanced Track (2 weeks, 5 hours/week):**
- Week 5: Module 13 (Security & Cost)
- Week 6: Module 14 (Comprehensive Review) + Mock Exams

**Flexible Schedule**: Self-paced, work around your schedule

---

## üìñ Slide 25: Teaching Philosophy

### Commands First, Theory Second

**Why This Approach?**
1. **Build Muscle Memory**: Do first, understand why later
2. **Immediate Productivity**: Get results quickly
3. **Real-World Focus**: Production skills over academic theory
4. **Active Learning**: Hands-on practice drives retention

**Each Module Includes:**
- üéØ Clear learning goals
- üìù Key terms and definitions
- ‚å®Ô∏è Copy-paste commands
- ‚úÖ Verification steps
- üî¨ Mini-lab exercise (5-10 min)
- ‚ùì Quiz questions (5-10 questions)
- üîß Troubleshooting guide

**Pedagogy**: Learn by doing, not by reading

---

## üß™ Slide 26: Hands-On Mini-Labs

### Practice Makes Perfect

**Mini-Lab Structure:**
1. **Goal**: What you'll accomplish
2. **Setup**: Prerequisites and data
3. **Steps**: Numbered, copy-paste commands
4. **Verify**: Check your work
5. **Extend**: Optional challenges

**Example Mini-Labs:**
- Module 02: Create a reproducible Python environment
- Module 03: Version a dataset with DVC
- Module 04: Track an ML experiment with MLflow
- Module 05: Build an Airflow DAG
- Module 08: Deploy a model API
- Module 11: Create a Grafana dashboard

**Time**: 5-10 minutes per lab

---

## üìù Slide 27: Assessment Strategy

### Multiple Ways to Validate Learning

**Quizzes (70 questions total):**
- 5-10 questions per module
- Multiple choice and true/false
- Immediate feedback
- Covers key concepts and commands

**Mock Exams (2 exams):**
- 90 minutes each
- 100 points per exam
- Real-world scenarios
- Certification-style format

**Capstone Project:**
- End-to-end ML system
- Self-assessment rubric
- Portfolio-worthy deliverable

**Continuous Assessment:**
- Mini-labs after each module
- Verify steps ensure correctness
- Troubleshooting exercises

---

## üåê Slide 28: Quick Start Options

### Three Ways to Get Started

**Option 1: Local (Recommended for Beginners)**
```bash
git clone https://github.com/Dhananjaiah/mlops.git
cd mlops/project
docker compose up -d
make run-train
```
- ‚úÖ Fastest setup (< 5 minutes)
- ‚úÖ Runs on any laptop
- ‚úÖ All services included

**Option 2: Kubernetes (Intermediate)**
```bash
k3d cluster create mlops-cluster
kubectl create namespace mlops
kustomize build project/infra/k8s/overlays/dev | kubectl apply -f -
```
- ‚úÖ Learn container orchestration
- ‚úÖ Practice production patterns
- ‚úÖ Local Kubernetes cluster

**Option 3: Cloud (Advanced)**
- Deploy to AWS, GCP, or Azure
- Use managed services
- Real production environment

---

## üìÇ Slide 29: Repository Structure

### Organized for Easy Navigation

```
mlops/
‚îú‚îÄ‚îÄ course/              # 15 module files (.md)
‚îÇ   ‚îú‚îÄ‚îÄ 00-overview.md
‚îÇ   ‚îú‚îÄ‚îÄ 01-mlops-foundations.md
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ project/             # Capstone project
‚îÇ   ‚îú‚îÄ‚îÄ data/            # DVC-tracked datasets
‚îÇ   ‚îú‚îÄ‚îÄ src/             # Python source code
‚îÇ   ‚îú‚îÄ‚îÄ serving/         # API implementation
‚îÇ   ‚îú‚îÄ‚îÄ pipelines/       # Airflow/Kubeflow
‚îÇ   ‚îú‚îÄ‚îÄ infra/           # Terraform, K8s manifests
‚îÇ   ‚îú‚îÄ‚îÄ tests/           # Comprehensive tests
‚îÇ   ‚îî‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ cheatsheets/         # 4 quick references
‚îú‚îÄ‚îÄ troubleshooting/     # Issue resolution guide
‚îú‚îÄ‚îÄ exams/               # 2 mock exams
‚îî‚îÄ‚îÄ presentation/        # This slide deck! ‚≠ê NEW!
```

**Easy to Navigate**: Everything is organized by topic

---

## ü§ù Slide 30: Community & Support

### You're Not Learning Alone

**GitHub Resources:**
- üìñ Discussions: Ask questions, share projects
- üêõ Issues: Report bugs or unclear content
- üîß Pull Requests: Contribute improvements

**External Communities:**
- MLOps Community Slack (#course channel)
- Reddit: r/mlops
- Twitter: #MLOpsCourse

**Support Channels:**
1. Module troubleshooting sections
2. Comprehensive troubleshooting matrix
3. GitHub Discussions
4. Community Slack

**Office Hours**: (If teaching live, add schedule here)

---

## üéñÔ∏è Slide 31: Certifications & Next Steps

### After Completing This Course

**Recommended Certifications:**
- AWS Certified Machine Learning - Specialty
- Google Cloud Professional ML Engineer
- Microsoft Azure AI Engineer Associate
- Databricks Certified ML Professional

**Build Your Portfolio:**
- Complete capstone project
- Deploy a personal ML system
- Contribute to open-source MLOps tools
- Write blog posts about learnings

**Career Development:**
- Join MLOps meetups
- Speak at conferences
- Mentor others
- Land your dream MLOps role!

**Timeline**: Most students ready for certification in 3-6 months

---

## ‚öôÔ∏è Slide 32: Implementation Options

### Flexible Deployment Choices

**Cloud Providers:**
- **AWS**: SageMaker, EKS, S3, ECR
- **GCP**: Vertex AI, GKE, GCS, Artifact Registry
- **Azure**: ML Studio, AKS, Blob Storage, ACR

**Container Orchestration:**
- Kubernetes (production-grade)
- Docker Compose (local development)
- K3d/Minikube (learning)

**Storage Options:**
- Cloud object storage (S3, GCS, Azure Blob)
- MinIO (local S3-compatible)
- NFS for Kubernetes

**Flexibility**: Choose what fits your environment and budget

---

## üí° Slide 33: Key Principles

### MLOps Best Practices You'll Learn

1. **Version Everything**
   - Code (Git), Data (DVC), Models (MLflow)

2. **Automate Relentlessly**
   - Pipelines, testing, deployment, monitoring

3. **Monitor Continuously**
   - Metrics, logs, traces, alerts

4. **Test Thoroughly**
   - Unit tests, integration tests, model quality tests

5. **Document Comprehensively**
   - Code comments, API docs, runbooks, model cards

6. **Secure by Design**
   - Scan dependencies, manage secrets, audit access

7. **Optimize Costs**
   - Right-size resources, autoscale, use spot instances

8. **Fail Fast, Learn Faster**
   - Quick feedback loops, iterative improvement

---

## üîÑ Slide 34: The MLOps Cycle

### Continuous Learning Loop

```
   1. DATA                    8. MONITOR
      ‚Üì                          ‚Üë
   2. VALIDATE               7. DEPLOY
      ‚Üì                          ‚Üë
   3. TRAIN                  6. APPROVE
      ‚Üì                          ‚Üë
   4. EVALUATE               5. REGISTER
      ‚Üì____________________‚Üë

If drift detected ‚Üí Restart at step 1
```

**Key Points:**
- Not a linear process - it's a cycle
- Automation enables continuous improvement
- Monitoring provides feedback for next iteration
- Drift detection triggers retraining

**This is what production ML looks like!**

---

## üìä Slide 35: Success Metrics

### How to Measure Course Success

**Student Success Indicators:**
- ‚úÖ Complete all 15 modules
- ‚úÖ Pass mini-labs with verification
- ‚úÖ Score 80%+ on mock exams
- ‚úÖ Deploy working capstone project
- ‚úÖ Can troubleshoot common issues
- ‚úÖ Understand production ML architecture

**Skills Checklist:**
- [ ] Set up reproducible Python environment
- [ ] Version data with DVC
- [ ] Track experiments with MLflow
- [ ] Build training pipelines
- [ ] Deploy model APIs
- [ ] Implement monitoring
- [ ] Detect and handle drift
- [ ] Secure ML systems

**Portfolio Piece**: Fully functional MLOps system on GitHub

---

## üéØ Slide 36: Prerequisites & Setup

### What Students Need to Start

**Required Knowledge:**
- Basic Python (functions, classes, libraries)
- Basic Git (clone, commit, push, pull)
- Basic Docker (build, run, images)
- Basic Linux CLI (cd, ls, mkdir, cat)

**Optional (Helpful):**
- Machine learning basics
- Kubernetes concepts
- CI/CD experience

**Hardware Requirements:**
- **Minimum**: 8GB RAM, 4 CPU cores, 20GB disk
- **Recommended**: 16GB RAM, 8 CPU cores, 50GB disk
- **Cloud**: Any tier with Kubernetes support

**Software Setup:**
- Docker Desktop or Docker Engine
- Git
- Python 3.11+
- Code editor (VS Code recommended)

---

## üé¨ Slide 37: How to Use This Course

### Student Guide

**Recommended Approach:**
1. Read the module content (15-20 min)
2. Run all commands in "Hands-On" sections
3. Complete the mini-lab (5-10 min)
4. Take the module quiz
5. Review troubleshooting section
6. Move to next module

**Tips for Success:**
- Don't skip the hands-on exercises
- Type commands yourself (don't just copy-paste)
- Verify each step before moving forward
- Ask questions in the community
- Take breaks between modules
- Review previous modules periodically

**Time Management**: 2-3 modules per week is sustainable

---

## üìÖ Slide 38: Suggested Schedule

### 6-Week Learning Plan

**Week 1: Foundations**
- Day 1-2: Modules 00, 00.5 (Overview & Data Eng basics)
- Day 3-4: Module 01, 02 (Foundations & Environment)
- Day 5-6: Module 03, 04 (Data & Experiments)
- Day 7: Review & practice

**Week 2: Pipelines**
- Day 1-2: Module 05 (Orchestration)
- Day 3-4: Module 06 (Training & Evaluation)
- Day 5-6: Module 07 (Registry & Governance)
- Day 7: Review & practice

**Week 3: Serving**
- Day 1-2: Module 08 (APIs)
- Day 3-4: Module 09 (Batch & Streaming)
- Day 5-6: Module 10 (CI/CD)
- Day 7: Review & deploy to K8s

**Week 4: Production**
- Day 1-2: Module 11 (Monitoring)
- Day 3-4: Module 12 (Drift Detection)
- Day 5-6: Module 13 (Security & Cost)
- Day 7: Review & practice

**Week 5: Integration**
- Day 1-3: Module 14 (Comprehensive Review)
- Day 4-5: Complete capstone project
- Day 6-7: Troubleshoot and refine

**Week 6: Assessment**
- Day 1-2: Mock Exam 1
- Day 3-4: Mock Exam 2
- Day 5-6: Final project polish
- Day 7: Celebrate! üéâ

---

## üèÖ Slide 39: What Makes This Course Different

### Unique Value Propositions

**1. Commands-First Approach**
- Hands-on from day one
- Learn by doing, not just reading
- Build muscle memory

**2. Complete Production System**
- Not just models - full MLOps pipeline
- Real tools used in industry
- Portfolio-worthy project

**3. Beginner-Friendly Data Module**
- No ML background required
- Starts from absolute basics
- DevOps-friendly explanations

**4. Comprehensive Support**
- 50+ troubleshooting solutions
- Multiple cheatsheets
- Active community

**5. Modern Tech Stack**
- Latest tools and best practices
- Industry-standard technologies
- Cloud-agnostic approach

**6. Multiple Practice Environments**
- Local, Kubernetes, Cloud
- Start simple, level up
- Flexible learning path

---

## üéì Slide 40: Instructor Notes

### Teaching Tips for Educators

**Before Class:**
- Test all commands in your environment
- Spin up docker-compose stack
- Review module quiz answers
- Prepare common issue solutions

**During Class:**
- Live coding > Slides
- Encourage students to type along
- Show actual errors and how to fix them
- Use troubleshooting matrix in real-time

**Lab Sessions:**
- Pair programming works well
- Circulate and help debug
- Collect common issues
- Share solutions with whole class

**Assessment:**
- Use mini-labs for immediate feedback
- Mock exams for comprehensive assessment
- Capstone project for final evaluation
- Peer code reviews build community

**Office Hours:**
- Focus on troubleshooting
- Live debugging sessions
- Architecture discussions
- Career guidance

---

## üåü Slide 41: Student Success Stories

### What Students Have Built

*(Add real examples as they come in)*

**Example Projects Students Might Build:**
- Customer churn predictor (capstone)
- Fraud detection system
- Recommendation engine
- Image classification API
- Time series forecasting pipeline
- Sentiment analysis service
- Price prediction model
- Anomaly detection system

**Skills Gained:**
- End-to-end ML pipeline development
- Production deployment experience
- Real-world troubleshooting
- Portfolio-ready projects

**Career Outcomes:**
- ML Engineer roles
- MLOps Engineer positions
- Platform Engineer roles
- Data Scientist promotions

---

## üìñ Slide 42: Recommended Resources

### Extend Your Learning

**Books:**
- "Designing Machine Learning Systems" - Chip Huyen
- "Machine Learning Engineering" - Andriy Burkov
- "Building Machine Learning Powered Applications" - Emmanuel Ameisen
- "Reliable Machine Learning" - Cathy Chen, et al.

**Online Communities:**
- MLOps Community (mlops.community)
- Made With ML (madewithml.com)
- Chip Huyen's blog
- Eugene Yan's blog

**Tools Documentation:**
- MLflow: mlflow.org
- DVC: dvc.org
- Airflow: airflow.apache.org
- Kubernetes: kubernetes.io

**YouTube Channels:**
- MLOps Community
- Made With ML
- TechWorld with Nana
- DevOps Toolkit

---

## üîß Slide 43: Troubleshooting Preview

### Common Issues & Quick Fixes

**Issue 1: Docker Compose Won't Start**
- Check Docker is running
- Check ports aren't in use
- Run `docker compose down` first

**Issue 2: MLflow Can't Connect**
- Verify MLFLOW_TRACKING_URI
- Check service is running
- Test with curl

**Issue 3: DVC Push Fails**
- Check remote storage credentials
- Verify network connectivity
- Check DVC remote configuration

**Issue 4: Kubernetes Pod Won't Start**
- Check image pull policy
- Verify resource limits
- Review pod logs

**Full Matrix**: See troubleshooting/triage-matrix.md

---

## üíª Slide 44: Code Quality Standards

### What Students Will Practice

**Code Style:**
- PEP 8 compliance
- Type hints for clarity
- Docstrings for functions
- Meaningful variable names

**Testing:**
- Unit tests for functions
- Integration tests for pipelines
- Model quality tests
- API endpoint tests

**Pre-Commit Hooks:**
- Black (formatting)
- Ruff (linting)
- Mypy (type checking)
- Pytest (tests)

**Documentation:**
- README files
- API documentation
- Model cards
- Runbooks

**These are production standards!**

---

## üöÄ Slide 45: Getting Started Today

### Your First Steps

**1. Clone the Repository**
```bash
git clone https://github.com/Dhananjaiah/mlops.git
cd mlops
```

**2. Read the Overview**
```bash
cat course/00-overview.md
```

**3. Start the Stack**
```bash
cd project
docker compose up -d
```

**4. Verify Everything Works**
```bash
curl http://localhost:8000/health
curl http://localhost:5000
```

**5. Begin Module 00**
- Read through the content
- Set up your environment
- Complete the mini-lab

**Time to first working system: < 15 minutes!**

---

## üéâ Slide 46: Final Thoughts

### Ready to Master MLOps?

**What You're About to Learn:**
- Build production ML systems from scratch
- Use industry-standard tools and practices
- Deploy models that scale and monitor themselves
- Handle the full ML lifecycle

**What You'll Accomplish:**
- Complete 15 comprehensive modules
- Build a production-ready ML system
- Master 20+ MLOps tools
- Create a portfolio-worthy project

**What's Next:**
- Start with Module 00
- Join the community
- Ask questions freely
- Build amazing ML systems!

**Remember**: Commands first, theory second. Let's build something great together! üöÄ

---

## üìû Slide 47: Contact & Support

### Stay Connected

**Course Repository:**
https://github.com/Dhananjaiah/mlops

**Support Channels:**
- GitHub Discussions: Ask questions
- GitHub Issues: Report problems
- Community Slack: Real-time chat

**Course Maintainer:**
Dhananjaiah
- GitHub: @Dhananjaiah
- Repository: Dhananjaiah/mlops

**Contributing:**
- Found a typo? Submit a PR!
- Have a suggestion? Open an issue!
- Built something cool? Share in Discussions!

**License:** MIT - Feel free to use and adapt!

---

## üôè Slide 48: Acknowledgments

### Standing on Shoulders of Giants

**Open Source Tools:**
Thank you to maintainers of:
- MLflow, DVC, Evidently
- Airflow, Kubernetes
- FastAPI, Prometheus, Grafana
- And many more!

**MLOps Community:**
- Inspiration and feedback
- Best practices sharing
- Collaborative learning

**Contributors:**
- Everyone who submitted PRs
- Beta testers who found issues
- Students who asked great questions

**You Make This Course Better!**

---

## üìö Slide 49: Course Checklist

### Track Your Progress

**Phase 1: Foundations**
- [ ] Module 00: Overview
- [ ] Module 00.5: Data Engineering for Beginners
- [ ] Module 01: MLOps Foundations
- [ ] Module 02: Environment & Packaging
- [ ] Module 03: Data Versioning & Quality
- [ ] Module 04: Experiment Tracking

**Phase 2: Pipelines**
- [ ] Module 05: Pipelines & Orchestration
- [ ] Module 06: Training, Eval & Selection
- [ ] Module 07: Model Registry & Governance

**Phase 3: Serving**
- [ ] Module 08: Serving & APIs
- [ ] Module 09: Batch & Streaming
- [ ] Module 10: CI/CD & Environments

**Phase 4: Production**
- [ ] Module 11: Observability & Monitoring
- [ ] Module 12: Drift Detection & Retraining
- [ ] Module 13: Security, Compliance & Cost
- [ ] Module 14: Comprehensive Review

**Assessment**
- [ ] Mock Exam 1
- [ ] Mock Exam 2
- [ ] Capstone Project Complete

---

## üéØ Slide 50: Let's Get Started!

### Your MLOps Journey Begins Now

**Remember:**
‚úÖ Commands first, theory second
‚úÖ Practice makes perfect
‚úÖ Ask questions freely
‚úÖ Build, break, fix, learn
‚úÖ Share your progress
‚úÖ Help others along the way

**The Goal:**
Build production ML systems with confidence!

**Next Step:**
‚Üí Open course/00-overview.md
‚Üí Start your first mini-lab
‚Üí Join the community

**Welcome to MLOps! üöÄ**

*Let's turn ML experiments into production systems!*

---

## üìÑ Appendix: Quick Reference

### Essential Links

**Main Resources:**
- Course Repository: github.com/Dhananjaiah/mlops
- Course README: README.md
- Implementation Guide: IMPLEMENTATION_GUIDE.md
- Course Summary: COURSE_SUMMARY.md

**Cheatsheets:**
- Linux: cheatsheets/linux.md
- Python: cheatsheets/python-env.md
- DVC+MLflow: cheatsheets/dvc-mlflow.md
- Docker+K8s: cheatsheets/docker-k8s.md

**Support:**
- Troubleshooting: troubleshooting/triage-matrix.md
- Discussions: github.com/Dhananjaiah/mlops/discussions
- Issues: github.com/Dhananjaiah/mlops/issues

**Exams:**
- Mock Exam 1: exams/mock-exam-1.md
- Mock Exam 2: exams/mock-exam-2.md

---

*End of Presentation*

**Questions?**
