# Capstone Project: Churn Predictor

> ğŸ’¡ **Looking for step-by-step execution instructions?** See the [**Project Execution Guide**](../PROJECT_EXECUTION_GUIDE.md) for detailed instructions!

## ğŸ¯ Overview

**Churn Predictor** is a complete end-to-end MLOps system for predicting customer churn. It demonstrates all concepts from the MLOps course in a production-ready implementation.

### Features
- âœ… Data versioning with DVC
- âœ… Experiment tracking with MLflow
- âœ… Automated training pipelines (Airflow)
- âœ… Model registry and governance
- âœ… REST API serving (FastAPI)
- âœ… Batch scoring
- âœ… Drift detection and automated retraining
- âœ… Observability (Prometheus + Grafana)
- âœ… CI/CD (GitHub Actions)
- âœ… Security scanning and SBOM
- âœ… Multi-environment deployments (dev/staging/prod)

---

## ğŸ—ï¸ Architecture

```mermaid
graph TB
    A[Customer Data] --> B[DVC Storage]
    B --> C[Airflow: Training Pipeline]
    C --> D[Data Quality Checks]
    D --> E[Model Training]
    E --> F[MLflow Tracking]
    F --> G[Model Registry]
    G --> H{Approval Gate}
    H -->|Approved| I[FastAPI Serving]
    H -->|Rejected| E
    I --> J[Prometheus Metrics]
    J --> K[Grafana Dashboards]
    J --> L[Evidently Drift Detection]
    L -->|Drift Detected| C
    I --> M[Batch Scoring]
    I --> N[Real-time API]
```

---

## ğŸš€ Quick Start (Local)

### Prerequisites
- Docker & Docker Compose
- Python 3.11+
- Git

### 1. Clone and Setup
```bash
git clone https://github.com/Dhananjaiah/mlops.git
cd mlops/project

# Copy environment variables
cp .env.example .env

# Source variables
source .env
```

### 2. Start Local Stack
```bash
# Start all services
docker compose up -d

# Verify services
docker compose ps

# Check health
curl http://localhost:8000/health  # FastAPI
curl http://localhost:5000         # MLflow
curl http://localhost:9090         # Prometheus
curl http://localhost:3000         # Grafana (admin/admin)
```

### 3. Initialize Data
```bash
# Generate sample data
python scripts/generate_data.py

# Initialize DVC
dvc init
dvc remote add -d local /tmp/dvc-remote
dvc add data/raw/customers.csv
dvc push
```

### 4. Train Model
```bash
# Option 1: Direct training
python src/train.py

# Option 2: Via Airflow
# Open http://localhost:8080 (admin/admin)
# Trigger "train_churn_model" DAG
```

### 5. Test API
```bash
# Make prediction
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{
    "features": [
      [34, 12, 65.5],
      [45, 24, 89.0]
    ]
  }'

# Expected response:
# {"predictions": [0, 0], "model_version": "1.0"}
```

### 6. View Monitoring
```bash
# Grafana dashboards
open http://localhost:3000

# Prometheus metrics
open http://localhost:9090

# MLflow experiments
open http://localhost:5000
```

---

## ğŸ“ Project Structure

```
project/
â”œâ”€â”€ data/                        # Data directory (DVC tracked)
â”‚   â”œâ”€â”€ raw/                     # Raw customer data
â”‚   â”œâ”€â”€ processed/               # Preprocessed features
â”‚   â””â”€â”€ scored/                  # Batch predictions
â”œâ”€â”€ features/                    # Feature definitions (optional)
â”‚   â””â”€â”€ customer_features.py
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ train.py                 # Training script
â”‚   â”œâ”€â”€ preprocess.py            # Data preprocessing
â”‚   â”œâ”€â”€ api.py                   # FastAPI serving
â”‚   â”œâ”€â”€ batch_score.py           # Batch scoring
â”‚   â””â”€â”€ detect_drift.py          # Drift detection
â”œâ”€â”€ serving/                     # Serving configs
â”‚   â”œâ”€â”€ Dockerfile.api
â”‚   â””â”€â”€ kserve-inference.yaml
â”œâ”€â”€ pipelines/                   # Orchestration
â”‚   â”œâ”€â”€ airflow/
â”‚   â”‚   â””â”€â”€ train_pipeline.py
â”‚   â””â”€â”€ kubeflow/
â”‚       â””â”€â”€ train_pipeline.py
â”œâ”€â”€ models/                      # Model artifacts (DVC/MLflow tracked)
â”œâ”€â”€ infra/                       # Infrastructure as code
â”‚   â”œâ”€â”€ terraform/
â”‚   â”‚   â”œâ”€â”€ main.tf
â”‚   â”‚   â””â”€â”€ variables.tf
â”‚   â””â”€â”€ k8s/
â”‚       â”œâ”€â”€ base/
â”‚       â”‚   â”œâ”€â”€ deployment.yaml
â”‚       â”‚   â””â”€â”€ service.yaml
â”‚       â””â”€â”€ overlays/
â”‚           â”œâ”€â”€ dev/
â”‚           â””â”€â”€ prod/
â”œâ”€â”€ tests/                       # Tests
â”‚   â”œâ”€â”€ unit/                    # Unit tests
â”‚   â”œâ”€â”€ integration/             # Integration tests
â”‚   â””â”€â”€ model/                   # Model quality tests
â”œâ”€â”€ scripts/                     # Utility scripts
â”‚   â”œâ”€â”€ generate_data.py         # Generate sample data
â”‚   â”œâ”€â”€ seed_db.py               # Seed databases
â”‚   â”œâ”€â”€ smoke_test.sh            # Smoke tests
â”‚   â””â”€â”€ inject_failure.py        # Failure injection for testing
â”œâ”€â”€ configs/                     # Configuration files
â”‚   â”œâ”€â”€ model_config.yaml
â”‚   â””â”€â”€ environments/
â”‚       â”œâ”€â”€ dev.yaml
â”‚       â”œâ”€â”€ staging.yaml
â”‚       â””â”€â”€ prod.yaml
â”œâ”€â”€ notebooks/                   # Jupyter notebooks (exploration)
â”œâ”€â”€ runbook.md                   # SRE playbook
â”œâ”€â”€ docker-compose.yml           # Local development stack
â”œâ”€â”€ .env.example                 # Environment variables template
â”œâ”€â”€ pyproject.toml               # Python dependencies
â”œâ”€â”€ requirements-lock.txt        # Locked dependencies
â”œâ”€â”€ Makefile                     # Common commands
â””â”€â”€ README.md                    # This file
```

---

## ğŸ”§ Development

### Setup Development Environment
```bash
# Create virtual environment
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Install dependencies
pip install -e ".[dev]"

# Install pre-commit hooks
pre-commit install

# Run tests
pytest tests/ -v

# Run linters
black src/ tests/
ruff check src/ tests/
mypy src/
```

### Run Individual Components

#### Training
```bash
python src/train.py \
  --model-type rf \
  --n-estimators 100 \
  --max-depth 5
```

#### API Server
```bash
uvicorn src.api:app --reload --host 0.0.0.0 --port 8000
```

#### Batch Scoring
```bash
python src/batch_score.py \
  data/raw/customers.csv \
  data/scored/predictions.csv
```

#### Drift Detection
```bash
python src/detect_drift.py \
  data/baseline.csv \
  data/current.csv
```

---

## ğŸ³ Docker Commands

```bash
# Build images
docker build -f serving/Dockerfile.api -t churn-api:latest .
docker build -f Dockerfile.train -t churn-train:latest .

# Run training
docker run --rm -v $(pwd)/data:/app/data churn-train:latest

# Run API
docker run -d -p 8000:8000 \
  -e MLFLOW_TRACKING_URI=http://mlflow:5000 \
  churn-api:latest
```

---

## â˜¸ï¸ Kubernetes Deployment

### Development Environment
```bash
# Create namespace
kubectl create namespace mlops-dev

# Deploy with Kustomize
kubectl apply -k infra/k8s/overlays/dev/

# Verify
kubectl get pods -n mlops-dev
kubectl get svc -n mlops-dev

# Port forward
kubectl port-forward -n mlops-dev svc/mlops-api 8000:80
```

### Production Environment
```bash
# Create namespace
kubectl create namespace mlops-prod

# Deploy with Kustomize
kubectl apply -k infra/k8s/overlays/prod/

# Verify rollout
kubectl rollout status deployment/mlops-api -n mlops-prod

# Check autoscaler
kubectl get hpa -n mlops-prod
```

---

## ğŸ§ª Testing

### Unit Tests
```bash
pytest tests/unit/ -v --cov=src
```

### Integration Tests
```bash
pytest tests/integration/ -v
```

### Model Tests
```bash
pytest tests/model/ -v
```

### End-to-End Smoke Test
```bash
./scripts/smoke_test.sh
```

### Load Testing
```bash
locust -f tests/load/locustfile.py --host=http://localhost:8000
```

---

## ğŸ“Š Monitoring

### Metrics
Access Prometheus at http://localhost:9090

Key queries:
```promql
# Prediction rate
rate(predictions_total[5m])

# P95 latency
histogram_quantile(0.95, prediction_latency_seconds_bucket)

# Error rate
rate(api_errors_total[5m])

# Drift alerts
drift_detected
```

### Dashboards
Access Grafana at http://localhost:3000 (admin/admin)

Pre-configured dashboards:
- ML API Performance
- Model Metrics
- Data Drift
- Infrastructure

### Alerts
Check AlertManager at http://localhost:9093

Configured alerts:
- High error rate (>5%)
- High latency (P95 >1s)
- Model not loaded
- Drift detected

---

## ğŸ”„ CI/CD

### GitHub Actions Workflow

Triggers on:
- Push to `main` â†’ Deploy to production
- Push to `develop` â†’ Deploy to dev
- Pull request â†’ Run tests and scans

Stages:
1. **Test**: Unit, integration, model tests
2. **Scan**: Trivy (CVEs), Gitleaks (secrets), SBOM generation
3. **Build**: Docker image build and push
4. **Deploy Dev**: Automatic deployment
5. **Deploy Prod**: Manual approval required

### Manual Deployment
```bash
# Build and push
make docker-build
make docker-push

# Deploy to dev
make deploy-dev

# Deploy to prod (requires approval)
make deploy-prod
```

---

## ğŸ” Security

### Pre-deployment Checks
```bash
# Scan for vulnerabilities
trivy image churn-api:latest --severity HIGH,CRITICAL

# Generate SBOM
syft churn-api:latest -o spdx-json=sbom.json

# Scan for secrets
gitleaks detect --source .

# Check dependencies
safety check
```

### RBAC
Kubernetes RBAC configured for:
- `mlops-deployer`: Can deploy to dev
- `mlops-admin`: Can deploy to prod
- `mlops-viewer`: Read-only access

---

## ğŸ’° Cost Optimization

### Resource Limits
```yaml
resources:
  requests:
    cpu: 100m
    memory: 256Mi
  limits:
    cpu: 1
    memory: 1Gi
```

### Autoscaling
```yaml
minReplicas: 2
maxReplicas: 10
targetCPUUtilizationPercentage: 70
```

### Cost Monitoring
- Kubecost for K8s: http://localhost:9003
- Cloud cost alerts configured for $1000/month threshold

---

## ğŸ“š Documentation

- [Runbook](runbook.md) - SRE playbook for incidents
- [API Docs](http://localhost:8000/docs) - OpenAPI/Swagger
- [Model Card](models/model_card.md) - Model documentation
- [Architecture Decision Records](docs/adr/) - Design decisions

---

## ğŸ“ Learning Objectives

By completing this project, you will:
- âœ… Build end-to-end ML systems from scratch
- âœ… Version data, code, and models
- âœ… Automate training and deployment
- âœ… Monitor models in production
- âœ… Handle drift and retrain automatically
- âœ… Implement security best practices
- âœ… Deploy to Kubernetes with CI/CD
- âœ… Troubleshoot production issues

---

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make changes and test
4. Submit pull request with tests and documentation

---

## ğŸ“ License

MIT License - see LICENSE file

---

## ğŸ†˜ Support

- Issues: https://github.com/Dhananjaiah/mlops/issues
- Discussions: https://github.com/Dhananjaiah/mlops/discussions
- Slack: MLOps Community

---

## ğŸ‰ Next Steps

1. Complete the end-to-end workflow
2. Experiment with different models
3. Add new features or data sources
4. Deploy to a cloud provider
5. Share your learnings with the community!

**Happy MLOps! ğŸš€**
